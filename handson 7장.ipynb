{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이썬 ≥3.5 필수\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# 사이킷런 ≥0.20 필수\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# 공통 모듈 임포트\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# 노트북 실행 결과를 동일하게 유지하기 위해\n",
    "np.random.seed(42)\n",
    "\n",
    "# 깔끔한 그래프 출력을 위해\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# 그림을 저장할 위치\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"ensembles\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"그림 저장:\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.1 투표기반 분류기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_moons\n",
    "\n",
    "X,y = make_moons(n_samples=500,noise=0.3,random_state=42)\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 하드보팅 (예측을 모아 가장 많은 숫자를 결과로)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "log_clf = LogisticRegression(solver=\"lbfgs\",random_state=42)\n",
    "rnd_clf = RandomForestClassifier(n_estimators=100,random_state=42)\n",
    "svm_clf = SVC(gamma=\"scale\", random_state=42)\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('lr',log_clf),('rf',rnd_clf),(\"svc\",svm_clf)],\n",
    "    voting=\"hard\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr', LogisticRegression(random_state=42)),\n",
       "                             ('rf', RandomForestClassifier(random_state=42)),\n",
       "                             ('svc', SVC(random_state=42))])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.864\n",
      "RandomForestClassifier 0.896\n",
      "SVC 0.896\n",
      "VotingClassifier 0.912\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for clf in (log_clf,rnd_clf,svm_clf,voting_clf):\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 소프트보팅(클래스의 확률을 평균내어 가장 확률 높은 클래스를 예측)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('log', LogisticRegression(random_state=42)),\n",
       "                             ('RF', RandomForestClassifier(random_state=42)),\n",
       "                             ('SVC', SVC(probability=True, random_state=42))],\n",
       "                 voting='soft')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_clf = LogisticRegression(solver=\"lbfgs\",random_state=42)\n",
    "rnd_clf = RandomForestClassifier(n_estimators=100,random_state=42)\n",
    "svm_clf = SVC(probability=True,gamma=\"scale\",random_state=42)\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "estimators=[(\"log\",log_clf),(\"RF\",rnd_clf),(\"SVC\",svm_clf)],\n",
    "    voting=\"soft\"\n",
    ")\n",
    "voting_clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.864\n",
      "RandomForestClassifier 0.896\n",
      "SVC 0.896\n",
      "VotingClassifier 0.92\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for clf in (log_clf,rnd_clf,svm_clf,voting_clf):\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__,accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.2 배깅과 페이스팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#배깅 : 같은 모델, 중복 샘플링(bootstrap) bootstrap = True\n",
    "#페이스팅 : 같은 모델, 중복 불허 bootstrap = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 배깅, 500개 결정트리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "bag_clf = BaggingClassifier(\n",
    "DecisionTreeClassifier(),n_estimators=500,\n",
    "max_samples = 100, bootstrap=True, n_jobs = -1    \n",
    ")\n",
    "\n",
    "bag_clf.fit(X_train,y_train)\n",
    "y_pred = bag_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.904\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 결정트리 1개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.856"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_clf =DecisionTreeClassifier(random_state=42)\n",
    "tree_clf.fit(X_train,y_train)\n",
    "y_pred_tree = tree_clf.predict(X_test)\n",
    "accuracy_score(y_test,y_pred_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2.2 oob 평가 (out of bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8986666666666666"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#특정 샘플이 선택될 확률은 63%에 수렴\n",
    "#따라서 한번도 선택되지 않은 샘플을 oob 샘플 이라고 함.\n",
    "#oob 샘플을 사용하여 검증할 수 있음 oob_score =True\n",
    "\n",
    "bag_clf = BaggingClassifier(\n",
    "DecisionTreeClassifier(),n_estimators=500,\n",
    "    bootstrap=True,oob_score=True,random_state=40\n",
    ")\n",
    "\n",
    "bag_clf.fit(X_train,y_train)\n",
    "bag_clf.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.32275132, 0.67724868],\n",
       "       [0.34117647, 0.65882353],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.09497207, 0.90502793],\n",
       "       [0.31147541, 0.68852459],\n",
       "       [0.01754386, 0.98245614],\n",
       "       [0.97109827, 0.02890173],\n",
       "       [0.97765363, 0.02234637],\n",
       "       [0.74404762, 0.25595238],\n",
       "       [0.        , 1.        ],\n",
       "       [0.7173913 , 0.2826087 ],\n",
       "       [0.85026738, 0.14973262],\n",
       "       [0.97222222, 0.02777778],\n",
       "       [0.0625    , 0.9375    ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.97837838, 0.02162162],\n",
       "       [0.94642857, 0.05357143],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01704545, 0.98295455],\n",
       "       [0.39473684, 0.60526316],\n",
       "       [0.88700565, 0.11299435],\n",
       "       [1.        , 0.        ],\n",
       "       [0.97790055, 0.02209945],\n",
       "       [0.        , 1.        ],\n",
       "       [0.99428571, 0.00571429],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.62569832, 0.37430168],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.13402062, 0.86597938],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.38251366, 0.61748634],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.27093596, 0.72906404],\n",
       "       [0.34146341, 0.65853659],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.00531915, 0.99468085],\n",
       "       [0.98843931, 0.01156069],\n",
       "       [0.91428571, 0.08571429],\n",
       "       [0.97282609, 0.02717391],\n",
       "       [0.98019802, 0.01980198],\n",
       "       [0.        , 1.        ],\n",
       "       [0.07361963, 0.92638037],\n",
       "       [0.98019802, 0.01980198],\n",
       "       [0.0052356 , 0.9947644 ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.97790055, 0.02209945],\n",
       "       [0.8       , 0.2       ],\n",
       "       [0.42424242, 0.57575758],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.66477273, 0.33522727],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.86781609, 0.13218391],\n",
       "       [1.        , 0.        ],\n",
       "       [0.56725146, 0.43274854],\n",
       "       [0.1576087 , 0.8423913 ],\n",
       "       [0.66492147, 0.33507853],\n",
       "       [0.91709845, 0.08290155],\n",
       "       [0.        , 1.        ],\n",
       "       [0.16759777, 0.83240223],\n",
       "       [0.87434555, 0.12565445],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.995     , 0.005     ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.07878788, 0.92121212],\n",
       "       [0.05418719, 0.94581281],\n",
       "       [0.29015544, 0.70984456],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.83040936, 0.16959064],\n",
       "       [0.01092896, 0.98907104],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.21465969, 0.78534031],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.94660194, 0.05339806],\n",
       "       [0.77094972, 0.22905028],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.16574586, 0.83425414],\n",
       "       [0.65306122, 0.34693878],\n",
       "       [0.        , 1.        ],\n",
       "       [0.02564103, 0.97435897],\n",
       "       [0.50555556, 0.49444444],\n",
       "       [1.        , 0.        ],\n",
       "       [0.03208556, 0.96791444],\n",
       "       [0.99435028, 0.00564972],\n",
       "       [0.23699422, 0.76300578],\n",
       "       [0.49509804, 0.50490196],\n",
       "       [0.9947644 , 0.0052356 ],\n",
       "       [0.00555556, 0.99444444],\n",
       "       [0.98963731, 0.01036269],\n",
       "       [0.26153846, 0.73846154],\n",
       "       [0.92972973, 0.07027027],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.80113636, 0.19886364],\n",
       "       [1.        , 0.        ],\n",
       "       [0.0106383 , 0.9893617 ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.98181818, 0.01818182],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01036269, 0.98963731],\n",
       "       [0.97752809, 0.02247191],\n",
       "       [0.99453552, 0.00546448],\n",
       "       [0.01960784, 0.98039216],\n",
       "       [0.17857143, 0.82142857],\n",
       "       [0.98387097, 0.01612903],\n",
       "       [0.29533679, 0.70466321],\n",
       "       [0.98295455, 0.01704545],\n",
       "       [0.        , 1.        ],\n",
       "       [0.00561798, 0.99438202],\n",
       "       [0.75690608, 0.24309392],\n",
       "       [0.38624339, 0.61375661],\n",
       "       [0.40625   , 0.59375   ],\n",
       "       [0.87368421, 0.12631579],\n",
       "       [0.92462312, 0.07537688],\n",
       "       [0.05181347, 0.94818653],\n",
       "       [0.82802548, 0.17197452],\n",
       "       [0.01546392, 0.98453608],\n",
       "       [0.        , 1.        ],\n",
       "       [0.02298851, 0.97701149],\n",
       "       [0.9726776 , 0.0273224 ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01041667, 0.98958333],\n",
       "       [0.        , 1.        ],\n",
       "       [0.03804348, 0.96195652],\n",
       "       [0.02040816, 0.97959184],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.94915254, 0.05084746],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.99462366, 0.00537634],\n",
       "       [0.        , 1.        ],\n",
       "       [0.39378238, 0.60621762],\n",
       "       [0.33152174, 0.66847826],\n",
       "       [0.00609756, 0.99390244],\n",
       "       [0.        , 1.        ],\n",
       "       [0.3172043 , 0.6827957 ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.00588235, 0.99411765],\n",
       "       [0.        , 1.        ],\n",
       "       [0.98924731, 0.01075269],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.62893082, 0.37106918],\n",
       "       [0.92344498, 0.07655502],\n",
       "       [0.        , 1.        ],\n",
       "       [0.99526066, 0.00473934],\n",
       "       [1.        , 0.        ],\n",
       "       [0.98888889, 0.01111111],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.06989247, 0.93010753],\n",
       "       [1.        , 0.        ],\n",
       "       [0.03608247, 0.96391753],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.02185792, 0.97814208],\n",
       "       [1.        , 0.        ],\n",
       "       [0.95808383, 0.04191617],\n",
       "       [0.78362573, 0.21637427],\n",
       "       [0.56650246, 0.43349754],\n",
       "       [0.        , 1.        ],\n",
       "       [0.18023256, 0.81976744],\n",
       "       [1.        , 0.        ],\n",
       "       [0.93121693, 0.06878307],\n",
       "       [0.97175141, 0.02824859],\n",
       "       [1.        , 0.        ],\n",
       "       [0.00531915, 0.99468085],\n",
       "       [0.        , 1.        ],\n",
       "       [0.43010753, 0.56989247],\n",
       "       [0.85858586, 0.14141414],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.00558659, 0.99441341],\n",
       "       [0.        , 1.        ],\n",
       "       [0.96923077, 0.03076923],\n",
       "       [0.        , 1.        ],\n",
       "       [0.21649485, 0.78350515],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.98477157, 0.01522843],\n",
       "       [0.8       , 0.2       ],\n",
       "       [0.99441341, 0.00558659],\n",
       "       [0.        , 1.        ],\n",
       "       [0.09497207, 0.90502793],\n",
       "       [0.99492386, 0.00507614],\n",
       "       [0.01714286, 0.98285714],\n",
       "       [0.        , 1.        ],\n",
       "       [0.02747253, 0.97252747],\n",
       "       [1.        , 0.        ],\n",
       "       [0.77005348, 0.22994652],\n",
       "       [0.        , 1.        ],\n",
       "       [0.90229885, 0.09770115],\n",
       "       [0.98387097, 0.01612903],\n",
       "       [0.22222222, 0.77777778],\n",
       "       [0.20348837, 0.79651163],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.20338983, 0.79661017],\n",
       "       [0.98181818, 0.01818182],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.98969072, 0.01030928],\n",
       "       [0.        , 1.        ],\n",
       "       [0.48663102, 0.51336898],\n",
       "       [1.        , 0.        ],\n",
       "       [0.00529101, 0.99470899],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.08379888, 0.91620112],\n",
       "       [0.12352941, 0.87647059],\n",
       "       [0.99415205, 0.00584795],\n",
       "       [0.03517588, 0.96482412],\n",
       "       [1.        , 0.        ],\n",
       "       [0.39790576, 0.60209424],\n",
       "       [0.05434783, 0.94565217],\n",
       "       [0.53191489, 0.46808511],\n",
       "       [0.51898734, 0.48101266],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.60869565, 0.39130435],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.24157303, 0.75842697],\n",
       "       [0.81578947, 0.18421053],\n",
       "       [0.08717949, 0.91282051],\n",
       "       [0.99453552, 0.00546448],\n",
       "       [0.82142857, 0.17857143],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.11904762, 0.88095238],\n",
       "       [0.04188482, 0.95811518],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.89150943, 0.10849057],\n",
       "       [0.19230769, 0.80769231],\n",
       "       [0.95238095, 0.04761905],\n",
       "       [0.00515464, 0.99484536],\n",
       "       [0.59375   , 0.40625   ],\n",
       "       [0.07692308, 0.92307692],\n",
       "       [0.99484536, 0.00515464],\n",
       "       [0.83684211, 0.16315789],\n",
       "       [0.        , 1.        ],\n",
       "       [0.99484536, 0.00515464],\n",
       "       [0.95360825, 0.04639175],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.26395939, 0.73604061],\n",
       "       [0.98461538, 0.01538462],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.00574713, 0.99425287],\n",
       "       [0.85142857, 0.14857143],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.75301205, 0.24698795],\n",
       "       [0.8969697 , 0.1030303 ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.75555556, 0.24444444],\n",
       "       [0.48863636, 0.51136364],\n",
       "       [0.        , 1.        ],\n",
       "       [0.92473118, 0.07526882],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.87709497, 0.12290503],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.74752475, 0.25247525],\n",
       "       [0.09146341, 0.90853659],\n",
       "       [0.42268041, 0.57731959],\n",
       "       [0.22395833, 0.77604167],\n",
       "       [0.        , 1.        ],\n",
       "       [0.87046632, 0.12953368],\n",
       "       [0.78212291, 0.21787709],\n",
       "       [0.00507614, 0.99492386],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.02884615, 0.97115385],\n",
       "       [0.96      , 0.04      ],\n",
       "       [0.93478261, 0.06521739],\n",
       "       [1.        , 0.        ],\n",
       "       [0.50731707, 0.49268293],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01604278, 0.98395722],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.96987952, 0.03012048],\n",
       "       [0.        , 1.        ],\n",
       "       [0.05172414, 0.94827586],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.99494949, 0.00505051],\n",
       "       [0.01675978, 0.98324022],\n",
       "       [1.        , 0.        ],\n",
       "       [0.14583333, 0.85416667],\n",
       "       [0.        , 1.        ],\n",
       "       [0.00546448, 0.99453552],\n",
       "       [0.        , 1.        ],\n",
       "       [0.41836735, 0.58163265],\n",
       "       [0.13095238, 0.86904762],\n",
       "       [0.22110553, 0.77889447],\n",
       "       [1.        , 0.        ],\n",
       "       [0.97647059, 0.02352941],\n",
       "       [0.21195652, 0.78804348],\n",
       "       [0.98882682, 0.01117318],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.96428571, 0.03571429],\n",
       "       [0.34554974, 0.65445026],\n",
       "       [0.98235294, 0.01764706],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.99465241, 0.00534759],\n",
       "       [0.        , 1.        ],\n",
       "       [0.06043956, 0.93956044],\n",
       "       [0.98214286, 0.01785714],\n",
       "       [1.        , 0.        ],\n",
       "       [0.03108808, 0.96891192],\n",
       "       [0.58854167, 0.41145833]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf.oob_decision_function_\n",
    "\n",
    "#사용한 분류기가 predcit_proba 함수를 지원하기 떄문에 각 클래스에 해당할 확률 반환가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.912"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = bag_clf.predict(X_test)\n",
    "accuracy_score(y_test,y_pred)\n",
    "\n",
    "#실제로 검증한 oob_score와 비슷한 결과."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.3 랜덤 패치와 랜덤 서브스페이스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#랜덤패치 : 특성도 랜덤샘플링 훈련 샘플도 랜덤샘플링 \n",
    "#bootstrap= True\n",
    "#bootstrap_features=True\n",
    "#max_features는 1보다 작게\n",
    "\n",
    "\n",
    "#랜덤 서브스페이스 : 특성은 랜덤샘플링 훈련 램플은 X\n",
    "#bootstrap= False\n",
    "#bootstrap_features=True\n",
    "#max_features는 1보다 작게\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.4 랜덤 포레스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.912"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rnd_clf = RandomForestClassifier(n_estimators=500,n_jobs=-1,max_leaf_nodes=16,random_state=42)\n",
    "\n",
    "rnd_clf.fit(X_train,y_train)\n",
    "y_pred = rnd_clf.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bagging으로도 만들수 있음.\n",
    "\n",
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(max_leaf_nodes=16, random_state=42),\n",
    "    n_estimators=500, max_samples=1.0, bootstrap=True, random_state=42)\n",
    "#실제로 RandomForestClassifier는 DecisionTreeClassifier+BaggingClassifier를 최적화 해놓은 클래스.\n",
    "#따라서 두가지 클래스의 파라미터를 가지고있음.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_clf.fit(X_train,y_train)\n",
    "y_pred_rf=bag_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.952"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(y_pred == y_pred_rf) / len(y_pred) \n",
    "#거의 동일"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.4.2 특성중요도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepal length (cm) 0.09904503023511269\n",
      "sepal width (cm) 0.020384240464390652\n",
      "petal length (cm) 0.4318744899700101\n",
      "petal width (cm) 0.4486962393304866\n"
     ]
    }
   ],
   "source": [
    "#랜덤 포레스트의 모든 트리의 노드에서 지니불순도 감소량을 따져 특성 중요도를 측정\n",
    "#1로 정규화\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "rnd_clf=RandomForestClassifier(n_estimators=500,n_jobs=-1)\n",
    "rnd_clf.fit(iris[\"data\"],iris[\"target\"])\n",
    "\n",
    "for name, score in zip(iris[\"feature_names\"], rnd_clf.feature_importances_):\n",
    "    print(name,score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mnist의 특성중요도 확인해보기 : 어떤 픽셀이 중요한지/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "mnist = fetch_openml('mnist_784',version=1)\n",
    "mnist.target = mnist.target.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_clf= RandomForestClassifier(n_estimators=100,random_state=42)\n",
    "rnd_clf.fit(mnist['data'],mnist['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_digit(data):\n",
    "    image = data.reshape(28,28)\n",
    "    plt.imshow(image,cmap=mpl.cm.hot,\n",
    "              interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "그림 저장: mnist_feature_importance_plot\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_digit(rnd_clf.feature_importances_)\n",
    "\n",
    "cbar = plt.colorbar(ticks=[rnd_clf.feature_importances_.min(),rnd_clf.feature_importances_.max()])\n",
    "#오른쪽 컬러바\n",
    "cbar.ax.set_yticklabels([\"not important\",\"very important\"])\n",
    "\n",
    "save_fig(\"mnist_feature_importance_plot\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.5 부스팅"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.5.1 에이다부스트 (adaptive boosting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1),\n",
       "                   learning_rate=0.5, n_estimators=200)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#약한 학습기를 여러개 연결하여 강한 학습기를 만듦.\n",
    "#이전 모델이 과소적합(오류)했던 훈련샘플의 가중치를 높이는것.\n",
    "#해당 예측기의 에러율로 가중치를 구하고, 그 가중치를 고려해 훈련샘플의 가중치를 업데이트\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada_clf = AdaBoostClassifier(\n",
    "DecisionTreeClassifier(max_depth=1),n_estimators=200,\n",
    "    algorithm = \"SAMME.R\", learning_rate=0.5\n",
    "    \n",
    "    \n",
    "    #SAMMME.R 은 predict_proba를 지원하는 모델일때.\n",
    ")\n",
    "\n",
    "ada_clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.5.2 그레디언트 부스팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adaboost --> 샘플의 가중치 업데이트\n",
    "#gradient boost --> 이전 모델의 잔차를 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "X = np.random.rand(100, 1) - 0.5\n",
    "y = 3*X[:, 0]**2 + 0.05 * np.random.randn(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 직접 GBRT 만들어보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_depth=2)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_reg1 = DecisionTreeRegressor(max_depth=2)\n",
    "tree_reg1.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_depth=2, random_state=42)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2 = y - tree_reg1.predict(X)\n",
    "tree_reg2 = DecisionTreeRegressor(max_depth=2, random_state=42)\n",
    "tree_reg2.fit(X, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_depth=2, random_state=42)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y3 = y2 - tree_reg2.predict(X)\n",
    "tree_reg3 = DecisionTreeRegressor(max_depth=2,random_state=42)\n",
    "tree_reg3.fit(X,y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = np.array([[0.8]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = sum(tree.predict(X_new) for tree in (tree_reg1,tree_reg2,tree_reg3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.75026781])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GBRT사용법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(learning_rate=1.0, max_depth=2, n_estimators=3,\n",
       "                          random_state=42)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gbrt = GradientBoostingRegressor(max_depth=2,n_estimators=3,learning_rate=1.0, random_state=42)\n",
    "gbrt.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 조기 종료를 사용한 그레디언트 부스팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(max_depth=2, n_estimators=56, random_state=42)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#learning_rate는 각 트리의 기여정도를 정함.\n",
    "#낮으면 많은 트리가 필요해지지만 성능은좋아짐.\n",
    "\n",
    "#트리가 너무 많으면 과소적합. 많으면 과대적합 가능.\n",
    "\n",
    "#최적의 트리 수를 정하기 위해 earlystoping 사용\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X_train,X_val,y_train,y_val = train_test_split(X,y,random_state=49)\n",
    "\n",
    "#트리를 여러개 만들어놓음\n",
    "gbrt =GradientBoostingRegressor(max_depth=2,n_estimators=120,random_state=42)\n",
    "gbrt.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "errors =[mean_squared_error(y_val,y_pred) \n",
    "        for y_pred in gbrt.staged_predict(X_val)]\n",
    "#staged_predict를 통해 각 학습단계(트리 수) 마다 모든 예측기를 순회하며 점수계산\n",
    "#여기선 mse\n",
    "#ex) 2개일떄 1~2 순회. 예측 -->점수 \n",
    "#3개일때 1~3순회. 예측 --> 점수\n",
    "#4개일떄 1~4순회. 예측 --> 점수\n",
    "\n",
    "bst_n_estimators =np.argmin(errors) + 1\n",
    "gbrt_best = GradientBoostingRegressor(max_depth=2, n_estimators=bst_n_estimators , random_state=42)\n",
    "gbrt_best.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_error = np.min(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#트리를 여러개 훈련시켜놓지않고\n",
    "#훈련을 중지하는 방법도 가능. warm_start=True로 하여 기존 트리를 유지하면서 훈련을 추가\n",
    "\n",
    "gbrt = GradientBoostingRegressor(max_depth=2, warm_start=True,random_state=42)\n",
    "\n",
    "min_val_error = float(\"inf\")\n",
    "error_going_up = 0\n",
    "\n",
    "for n_estimators in range(1,120):\n",
    "    gbrt.n_estimators=n_estimators\n",
    "    gbrt.fit(X_train,y_train)\n",
    "    y_pred = gbrt.predict(X_val)\n",
    "    val_error = mean_squared_error(y_val,y_pred)\n",
    "    \n",
    "    if val_error < min_val_error:\n",
    "        min_val_error = val_error\n",
    "        error_going_up = 0\n",
    "    else:\n",
    "        error_going_up +=1\n",
    "        if error_going_up==5:\n",
    "            break\n",
    "    #다섯번 연속으로 에러가 오르면 early stopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n"
     ]
    }
   ],
   "source": [
    "print(gbrt.n_estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minumum validation MSE : 0.002712853325235463\n"
     ]
    }
   ],
   "source": [
    "print(\"minumum validation MSE :\", min_val_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "\n",
    "#익스트림 그레디언트 부스팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MSE:  0.004000408205406276\n"
     ]
    }
   ],
   "source": [
    "xgb_reg = xgboost.XGBRegressor(random_state=42)\n",
    "xgb_reg.fit(X_train,y_train)\n",
    "y_pred = xgb_reg.predict(X_val)\n",
    "val_error = mean_squared_error(y_val, y_pred)\n",
    "print(\"Validation MSE: \",val_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:0.22834\n",
      "[1]\tvalidation_0-rmse:0.16224\n",
      "[2]\tvalidation_0-rmse:0.11843\n",
      "[3]\tvalidation_0-rmse:0.08760\n",
      "[4]\tvalidation_0-rmse:0.06848\n",
      "[5]\tvalidation_0-rmse:0.05709\n",
      "[6]\tvalidation_0-rmse:0.05297\n",
      "[7]\tvalidation_0-rmse:0.05129\n",
      "[8]\tvalidation_0-rmse:0.05155\n",
      "Validation MSE: 0.002630868681577655\n"
     ]
    }
   ],
   "source": [
    "xgb_reg.fit(X_train, y_train,\n",
    "                eval_set=[(X_val, y_val)], early_stopping_rounds=2)\n",
    "y_pred = xgb_reg.predict(X_val)                                                                                        \n",
    "val_error = mean_squared_error(y_val, y_pred)  # 책에 없음\n",
    "print(\"Validation MSE:\", val_error)            # 책에 없음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 연습문제 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 문제: MNIST 데이터를 불러들여 훈련 세트, 검증 세트, 테스트 세트로 나눕니다(예를 들면 훈련에 40,000개 샘플, 검증에 10,000개 샘플, 테스트에 10,000개 샘플)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_val,X_test,y_train_val,y_test = train_test_split(\n",
    "mnist.data, mnist.target,test_size = 10000, random_state=42\n",
    ")\n",
    "\n",
    "X_train,X_val,y_train,y_val = train_test_split(\n",
    "X_train_val,y_train_val,test_size=10000,random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 문제: 그런 다음 랜덤 포레스트 분류기, 엑스트라 트리 분류기, SVM 같은 여러 종류의 분류기를 훈련시킵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "random_forest_clf = RandomForestClassifier(n_estimators=100,random_state=42)\n",
    "extra_tree_clf = ExtraTreesClassifier(n_estimators=100,random_state=42)\n",
    "svm_clf = LinearSVC(random_state=42)\n",
    "mlp_clf = MLPClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the RandomForestClassifier(random_state=42)\n",
      "Training the ExtraTreesClassifier(random_state=42)\n",
      "Training the LinearSVC(random_state=42)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\9sup2\\anaconda3\\envs\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the MLPClassifier(random_state=42)\n"
     ]
    }
   ],
   "source": [
    "estimators =[random_forest_clf,extra_tree_clf,svm_clf,mlp_clf]\n",
    "for estimator in estimators:\n",
    "    print(\"Training the\",estimator)\n",
    "    estimator.fit(X_train,y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9692, 0.9715, 0.8695, 0.9606]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[estimator.score(X_val,y_val) for estimator in estimators]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### svm은 다른 분류기에 비해 성능이 떨어짐 하지만, voting에 도움을 줄수도 있으니 넣어봄"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 문제: 그리고 검증 세트에서 개개의 분류기보다 더 높은 성능을 내도록 이들을 간접 또는 직접 투표 분류기를 사용하는 앙상블로 연결해보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "named_estimators = [\n",
    "    (\"random_forest_clf\",random_forest_clf),\n",
    "    (\"extra_tree_clf\",extra_tree_clf),\n",
    "    (\"svm_clf\",svm_clf),\n",
    "    (\"mlp_clf\",mlp_clf)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_clf = VotingClassifier(named_estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\9sup2\\anaconda3\\envs\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('random_forest_clf',\n",
       "                              RandomForestClassifier(random_state=42)),\n",
       "                             ('extra_tree_clf',\n",
       "                              ExtraTreesClassifier(random_state=42)),\n",
       "                             ('svm_clf', LinearSVC(random_state=42)),\n",
       "                             ('mlp_clf', MLPClassifier(random_state=42))])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf.score(X_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9692, 0.9715, 0.8695, 0.9606]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[estimator.score(X_val,y_val) for estimator in voting_clf.estimators_]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM 모델을 제거하면 더 좋아지는지 확인. \n",
    "다음과 같이 set_params()를 사용하여 None으로 지정하면 특정 예측기를 제외시킬 수 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('random_forest_clf',\n",
       "                              RandomForestClassifier(random_state=42)),\n",
       "                             ('extra_tree_clf',\n",
       "                              ExtraTreesClassifier(random_state=42)),\n",
       "                             ('svm_clf', None),\n",
       "                             ('mlp_clf', MLPClassifier(random_state=42))])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf.set_params(svm_clf=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('random_forest_clf', RandomForestClassifier(random_state=42)),\n",
       " ('extra_tree_clf', ExtraTreesClassifier(random_state=42)),\n",
       " ('svm_clf', None),\n",
       " ('mlp_clf', MLPClassifier(random_state=42))]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf.estimators\n",
    "#예측기 목록 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[RandomForestClassifier(random_state=42),\n",
       " ExtraTreesClassifier(random_state=42),\n",
       " LinearSVC(random_state=42),\n",
       " MLPClassifier(random_state=42)]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf.estimators_\n",
    "#훈련된 예측기엔 아직 svm이 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "del voting_clf.estimators_[2]\n",
    "#훈련된 목록에서도 삭제완료.(다시 학습해도 사라짐)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9737"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf.score(X_val,y_val)\n",
    "#0.97 --> 0.9737"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 훨씬 나아졌네요! SVM 모델이 성능을 저하시켰습니다. 이제 간접 투표 분류기를 사용해 보죠. 분류기를 다시 훈련시킬 필요는 없고 voting을 \"soft\"로 지정하면 됩니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_clf.voting=\"soft\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf.score(X_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#직접이 더 좋았음.(hard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 테스트 세트로 확인해보세요. 개개의 분류기와 비교해서 성능이 얼마나 향상되나요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9711"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf.voting= \"hard\"\n",
    "voting_clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9645, 0.9691, 0.9586]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[estimator.score(X_test,y_test) for estimator in voting_clf.estimators_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#voting이 조금이라도 더 좋았음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 연습문제 9 : 스태킹 앙상블"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 문제: 이전 연습문제의 각 분류기를 실행해서 검증 세트에서 예측을 만들고 그 결과로 새로운 훈련 세트를 만들어보세요. 각 훈련 샘플은 하나의 이미지에 대한 전체 분류기의 예측을 담은 벡터고 타깃은 이미지의 클래스입니다. 새로운 훈련 세트에 분류기 하나를 훈련시켜 보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(random_state=42)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [random_forest_clf, extra_tree_clf, svm_clf, mlp_clf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 4)\n"
     ]
    }
   ],
   "source": [
    "X_val_predictions = np.empty((len(X_val), len(estimators)), dtype=np.float32)\n",
    "print(X_val_predictions.shape) #10000,4\n",
    "\n",
    "for index, estimator in enumerate(estimators):\n",
    "    X_val_predictions[:, index] = estimator.predict(X_val)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5., 5., 5., 5.],\n",
       "       [8., 8., 8., 8.],\n",
       "       [2., 2., 2., 2.],\n",
       "       ...,\n",
       "       [7., 7., 7., 7.],\n",
       "       [6., 6., 6., 6.],\n",
       "       [7., 7., 7., 7.]], dtype=float32)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 예측결과값으로 블랜더 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=200, oob_score=True, random_state=42)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_forest_blender = RandomForestClassifier(n_estimators=200,oob_score=True,random_state=42)\n",
    "rnd_forest_blender.fit(X_val_predictions,y_val)\n",
    "#타겟은 그대로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9704"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_forest_blender.oob_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \n",
    "이 블렌더를 세밀하게 튜닝하거나 다른 종류의 블렌더(예를 들어, MLPClassifier)를 시도해 볼 수 있습니다. 그런 늘 하던대로 다음 교차 검증을 사용해 가장 좋은 것을 선택합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 테스트 세트에 앙상블을 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_predictions = np.empty((len(X_test),len(estimators)),dtype = np.float32)\n",
    "\n",
    "for index,estimator in enumerate(estimators):\n",
    "    X_test_predictions[:,index] = estimator.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rnd_forest_blender.predict(X_test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9688"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_forest_blender.score(X_test_predictions,y_test)\n",
    "#얘로도 가능하고 metrics.accuracy_score 도 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9688"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 이 스태킹 앙상블은 앞서 만든 투표 기반 분류기만큼 성능을 내지는 못합니다. 최선의 개별 분류기만큼 뛰어나지는 않습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "[env]",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
