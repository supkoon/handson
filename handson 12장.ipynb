{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"handson 12강","private_outputs":true,"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMyTqoRx5x3+8+ZUubQbaER"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"t5cHEfRa4Gr4"},"source":["# 파이썬 ≥3.5 필수\n","import sys\n","assert sys.version_info >= (3, 5)\n","\n","# 사이킷런 ≥0.20 필수\n","import sklearn\n","assert sklearn.__version__ >= \"0.20\"\n","\n","try:\n","    # %tensorflow_version은 코랩 명령입니다.\n","    %tensorflow_version 2.x\n","except Exception:\n","    pass\n","\n","# 이 노트북은 텐서플로 ≥2.4이 필요합니다\n","# 2.x 버전은 대부분 동일한 결과를 만들지만 몇 가지 버그가 있습니다.\n","import tensorflow as tf\n","from tensorflow import keras\n","assert tf.__version__ >= \"2.4\"\n","\n","# 공통 모듈 임포트\n","import numpy as np\n","import os\n","\n","# 노트북 실행 결과를 동일하게 유지하기 위해\n","np.random.seed(42)\n","tf.random.set_seed(42)\n","\n","# 깔끔한 그래프 출력을 위해\n","%matplotlib inline\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","mpl.rc('axes', labelsize=14)\n","mpl.rc('xtick', labelsize=12)\n","mpl.rc('ytick', labelsize=12)\n","\n","# 그림을 저장할 위치\n","PROJECT_ROOT_DIR = \".\"\n","CHAPTER_ID = \"deep\"\n","IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n","os.makedirs(IMAGES_PATH, exist_ok=True)\n","\n","def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n","    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n","    print(\"그림 저장:\", fig_id)\n","    if tight_layout:\n","        plt.tight_layout()\n","    plt.savefig(path, format=fig_extension, dpi=resolution)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OvIeOc4HFjO4"},"source":["# 12.2 넘파이처럼 텐서플로 사용하기"]},{"cell_type":"markdown","metadata":{"id":"TbKZr6ueFmuT"},"source":["### 12.2.1 텐서와 연산"]},{"cell_type":"code","metadata":{"id":"-MxPSdPI9zkH"},"source":["#텐서 2행 3열\n","tf.constant([[1.,2.,3.],[4.,5.,6.]])\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_ZYEpZW4F0cB"},"source":["#스칼라\n","tf.constant(42)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TOdIhFU2GKIS"},"source":["t=tf.constant([[1.,2.,3.],[4.,5.,6.]])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IByL5RnDGAo5"},"source":["t.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"d5LUVb0DGCtA"},"source":["t.dtype"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kdKE299XF5c3"},"source":["t[:,1:]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nDQyEIePGPeR"},"source":["t[:,1,tf.newaxis]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"o09huIR0GyCb"},"source":["단순한 연산 가능"]},{"cell_type":"code","metadata":{"id":"DSryKD6LGl_n"},"source":["t+10"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dzVktgFSGWrX"},"source":["tf.square(t)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aPfiYnLTG2FI"},"source":["# @ --> 행렬곱셈\n","#2x3 @ 3x2 = 2x2\n","\n","t @ tf.transpose(t) "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"A9_5pI_lHlEW"},"source":["### 12.2.2 텐서와 넘파이"]},{"cell_type":"code","metadata":{"id":"Nk_EdrH-HkHi"},"source":["a = np.array([2.,4.,5.])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9TqSU-8uG7IO"},"source":["tf.constant(a)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RXCwt7JXHwof"},"source":["t.numpy()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"stCKLiVRH1X6"},"source":["tf.square(a)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pa-uf4L2IDGX"},"source":["### 12.2.3 타입 변환"]},{"cell_type":"markdown","metadata":{"id":"mch83DHFIN_g"},"source":["성능저하를 방지하기 위해 텐서플로우는 타입변환을 자동으로하지않음."]},{"cell_type":"code","metadata":{"id":"g7N4sZJXIBT9"},"source":["t2 = tf.constant(40., dtype=tf.float64)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"W1WsspVXISSq"},"source":["#tf.cast를 이용해 형변환 가능\n","tf.constant(2.0) + tf.cast(t2,tf.float32)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CVnEJnmcIhv2"},"source":["### 12.2.4 변수"]},{"cell_type":"markdown","metadata":{"id":"dSWLVbNyIv_G"},"source":["텐서와 다르게 변수는 .assign()을 이용해 값을 바꿀수있음"]},{"cell_type":"code","metadata":{"id":"elVT-ikNId2y"},"source":["v = tf.Variable([1.,2.,3.],[4.,5.,6.])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"suHEv3KtIs0U"},"source":["v.assign(2*v)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZYJkwq6IJfe8"},"source":["# 12.3 사용자 정의 모델과 훈련 알고리즘"]},{"cell_type":"markdown","metadata":{"id":"Uh0E243AJiv0"},"source":["### 12.3.1 사용자 정의 손실 함수"]},{"cell_type":"code","metadata":{"id":"Uko9mdRxMVvs"},"source":["from sklearn.datasets import fetch_california_housing\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","\n","housing = fetch_california_housing()\n","X_train_full, X_test, y_train_full, y_test = train_test_split(\n","    housing.data, housing.target.reshape(-1, 1), random_state=42)\n","X_train, X_valid, y_train, y_valid = train_test_split(\n","    X_train_full, y_train_full, random_state=42)\n","\n","scaler = StandardScaler()\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_valid_scaled = scaler.transform(X_valid)\n","X_test_scaled = scaler.transform(X_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xkoxnenoJEb-"},"source":["#후버손실(임계값에 따라 mse,mae 사용)\n","\n","def huber_fn(y_true,y_pred):\n","  error = y_true =y_pred\n","  is_small_error =tf.abs(error)<1\n","  squared_loss =tf.square(error) /2\n","  linear_loss = tf.abs(error) -0.5\n","  return tf.where(is_small_error, squared_loss,linear_loss)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"waoEGhHoMdMK"},"source":["plt.figure(figsize=(8, 3.5))\n","z = np.linspace(-4, 4, 200)\n","plt.plot(z, huber_fn(0, z), \"b-\", linewidth=2, label=\"huber($z$)\")\n","plt.plot(z, z**2 / 2, \"b:\", linewidth=1, label=r\"$\\frac{1}{2}z^2$\")\n","plt.plot([-1, -1], [0, huber_fn(0., -1.)], \"r--\")\n","plt.plot([1, 1], [0, huber_fn(0., 1.)], \"r--\")\n","plt.gca().axhline(y=0, color='k')\n","plt.gca().axvline(x=0, color='k')\n","plt.axis([-4, 4, 0, 4])\n","plt.grid(True)\n","plt.xlabel(\"$z$\")\n","plt.legend(fontsize=14)\n","plt.title(\"Huber loss\", fontsize=14)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JfIOBH4tT55R"},"source":["input_shape = X_train.shape[1:]\r\n","\r\n","model = keras.models.Sequential([\r\n","    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\r\n","                       input_shape=input_shape),\r\n","    keras.layers.Dense(1),\r\n","])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AusL1jSeMEo4"},"source":["model.compile(loss=huber_fn, optimizer= 'nadam')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wlMm6tVVMWGE"},"source":["model = keras.models.Sequential(\n","    [keras.layers.Dense(30,activation=\"selu\", kernel_initializer=\"lecun_normal\",\n","                        input_shape=[8]),\n","     keras.layers.Dense(1)\n","                                      \n","                        ]\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ynVerDeGNKwG"},"source":["#후버로스 사용\n","model.compile(loss=huber_fn, optimizer= keras.optimizers.Nadam(),\n","              metrics=[\"mae\"])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GulL9UAqNTow"},"source":["model.fit(X_train_scaled,y_train,epochs=2,\n","          validation_data = (X_valid_scaled,y_valid))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"O1EMfF0NN1jZ"},"source":["### 12.3.2 사용자 정의 요소를 가진 모델을 저장하고 로드하기"]},{"cell_type":"code","metadata":{"id":"FQx-yXlOOT_f"},"source":["model.save(\"my_model_with_a_custom_loss.h5\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"10pGFcj4NbwZ"},"source":["#저장은 문제가 없지만\n","#로드는 함수이름과 실제 함수를 매핑한 딕셔너리를 전달해야함\n","model = keras.models.load_model(\"my_model_with_a_custom_loss.h5\",\n","                                custom_objects={\"huber_fn\":huber_fn})"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hhvXzmxAOvM9"},"source":["파라미터를 받는 로스 만들기"]},{"cell_type":"code","metadata":{"id":"FE3sP_QaOTFz"},"source":["def create_huber(threshold=1.0):\n","  def huber_fn(y_true,y_pred):\n","    error = y_true- y_pred\n","    is_small_error = tf.abs(error)<threshold\n","    squared_loss = tf.square(error)/2\n","    linear_loss = threshold * tf.abs(error) - threshold**2 / 2\n","    return tf.where(is_small_error,squared_loss,linear_loss)\n","  return huber_fn"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BuqKoWKYPjFT"},"source":["model.compile(loss=create_huber(2.0), optimizer=\"nadam\",metrics=[\"mae\"])\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"C6R0MhNhPpfc"},"source":["model.fit(X_train_scaled, y_train, epochs=2,\n","          validation_data=(X_valid_scaled, y_valid))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"J9-NeH0dPvwg"},"source":["model.save(\"my_model_with_a_custom_loss_threshold_2.h5\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"J54dZBOJQByu"},"source":["model = keras.models.load_model(\"my_model_with_a_custom_loss_threshold_2.h5\",\n","                                custom_objects={\"huber_fn\":create_huber(2.0)})\n","#새로 정의한 함수이름이 아닌 케라스 모델에서 사용했던 함수이름 huber_fn 사용"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"czS1sNgIQRhP"},"source":["model.fit(X_train_scaled,y_train,epochs=2,\n","          validation_data =(X_valid_scaled,y_valid))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MaX1BLO8RUWO"},"source":["keras.losses.Loss 클래스를 상속하여 키 이름지정 해결가능"]},{"cell_type":"code","metadata":{"id":"pfrJFyZaQugx"},"source":["class HuberLoss(keras.losses.Loss):\n","    def __init__(self, threshold=1.0, **kwargs):\n","        self.threshold = threshold\n","        super().__init__(**kwargs)\n","    def call(self, y_true, y_pred):\n","        error = y_true - y_pred\n","        is_small_error = tf.abs(error) < self.threshold\n","        squared_loss = tf.square(error) / 2\n","        linear_loss  = self.threshold * tf.abs(error) - self.threshold**2 / 2\n","        return tf.where(is_small_error, squared_loss, linear_loss)\n","    #get_config는 부모의 하이퍼파라미터 매핑된 딕셔너리 반환\n","    #이 딕셔너리에 새로운 하이퍼 파라미터 추가\n","    def get_config(self):\n","        base_config = super().get_config()\n","        return {**base_config, \"threshold\": self.threshold}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MkyZLYU7SADX"},"source":["input_shape = X_train_scaled.shape[1:]\n","model = keras.models.Sequential([\n","    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n","                       input_shape=input_shape),\n","    keras.layers.Dense(1),\n","])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"p2Z1veS2SW9t"},"source":["model.compile(loss=HuberLoss(2.), optimizer=\"nadam\", metrics=[\"mae\"])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Rs7OulyOSpIS"},"source":["model.fit(X_train_scaled, y_train, epochs=2,\n","          validation_data=(X_valid_scaled, y_valid))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xiXYclX1SwAr"},"source":["model.save(\"my_model_with_a_custom_loss_class.h5\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ED-3Ytp0UAgf"},"source":["model = keras.models.load_model(\"my_model_with_a_custom_loss_class.h5\",\n","                                custom_objects={\"HuberLoss\": HuberLoss})\n","#클래스 이름으로 가져옴"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VirD8vCtUCBM"},"source":["model.fit(X_train_scaled, y_train, epochs=2,\n","          validation_data=(X_valid_scaled, y_valid))\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6i4am1GoUcyj"},"source":["### 12.3.3 활성화 함수, 초기화, 규제, 제한을 커스터마이징 하기"]},{"cell_type":"code","metadata":{"id":"rNohr4bIUDKW"},"source":["#사용자 정의 활성화함수\n","def my_softplus(z):\n","  return tf.math.log(tf.exp(z)+1.0)\n","#사용자 정의 글로럿초기화(==xavier, 1/fan_avg)\n","def my_glorot_initializer(shape, dtype=tf.float32):\n","    stddev = tf.sqrt(2. / (shape[0] + shape[1]))\n","    return tf.random.normal(shape, stddev=stddev, dtype=dtype)\n","\n","#사용자 정의 l1규제\n","def my_l1_regularizer(weights):\n","  return tf.reduce_sum(tf.abs(0.01*weights))\n","#사용자 정의 양수 가중치만 남기기\n","def my_positive_weights(weights):\n","  return tf.where(weights<0., tf.zeros_like(weights), weights)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AHii3UC5XTy2"},"source":["layer = keras.layers.Dense(1, \n","                           activation=my_softplus,\n","                           kernel_initializer=my_glorot_initializer,\n","                           kernel_regularizer=my_l1_regularizer,\n","                           kernel_constraint=my_positive_weights)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PicDoTEMYhxY"},"source":["모델과 저장할 파라미터가 있을때."]},{"cell_type":"code","metadata":{"id":"d13dveFQYhhX"},"source":["class MyL1Regularizer(keras.regularizers.Regularizer):\n","  def __init__(self,factor):\n","    self.factor = factor\n","  def call(self,weights):\n","    return tf.reduce_sum(tf.abs(self.factor*weights))\n","  def get_config(self):\n","    return {\"factor\":self.factor}\n","    #다른 규제클래스를 상속하여 만들지 않았기떄문에 부모의 get_config 필요없음."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lTC4a0XJZOjd"},"source":["### 12.3.4 사용자 정의 지표"]},{"cell_type":"markdown","metadata":{"id":"CLbURM2xcYMB"},"source":["precision과 같은 스트리밍 지표는 누적되어야 함."]},{"cell_type":"code","metadata":{"id":"cVGVkCbwZNrz"},"source":["precision = tf.metrics.Precision()\n","precision([0, 1, 1, 1, 0, 1, 0, 1], [1, 1, 0, 1, 0, 1, 0, 1])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"euKDXQ3cX9M1"},"source":["precision([0, 1, 0, 0, 1, 0, 1, 1], [1, 0, 1, 1, 0, 0, 0, 0])\n","#누적되어 0.4가 아닌 0.5"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0L_xgyJ5bsZs"},"source":["#variable 을 통해 변수 확인\n","precision.variables"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"K2B5juLFb4AD"},"source":["#스트리밍 변수 초기화\n","precision.reset_states()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"F0wGYmRFcVNr"},"source":["스트리밍 지표 만들기"]},{"cell_type":"code","metadata":{"id":"jezpglJ8cRmv"},"source":["#전체 후버 손실과 처리한 샘플 수 기록\n","class HuberMetric(keras.metrics.Metric):\n","  def __init__(self,threshold=1.0, **kwargs):\n","    super().__init__(**kwargs)\n","    self.threshold = threshold\n","    self.huber_fn = create_huber(threshold)\n","    self.total = self.add_weight(\"total\", initializer=\"zeros\")\n","    self.count = self.add_weight(\"count\", initializer = \"zeros\")\n","  def update_state(self,y_true,y_pred,sample_weight=None):\n","    metric = self.huber_fn(y_true,y_pred)\n","    self.total.assign_add(tf.reduce_sum(metric))\n","    self.count.assign_add(tf.cast(tf.size(y_true), tf.float32))\n","  def result(self):\n","    return self.total / self.count\n","  def get_config(self):\n","    base_config = super().get_config()\n","    return {**base_config, \"threshold\":self.threshold}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5v_iCsqkkdOH"},"source":["m = HuberMetric(2.)\n","# total = 2 * |10 - 2| - 2²/2 = 14\n","# count = 1\n","# result = 14 / 1 = 14\n","m(tf.constant([[2.]]), tf.constant([[10.]]))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dzYrGunhlms8"},"source":["12.3.5 사용자 정의 층"]},{"cell_type":"markdown","metadata":{"id":"GafFVznOl_PC"},"source":["가중치가 없는 층은 keras.layers.lambda 사용 ex) Flatten,relu"]},{"cell_type":"code","metadata":{"id":"-FNCXepgl-8z"},"source":["exponential_layer =keras.layers.Lambda(lambda x: tf.exp(x))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jf3Az_UNlFHv"},"source":["model = keras.models.Sequential([\n","                                 keras.layers.Dense(30,activation=\"relu\",input_shape= input_shape),\n","                                 keras.layers.Dense(1),\n","                                 #사용\n","                                 exponential_layer\n","                                 \n","])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mW9GZsXim_m4"},"source":["상태가 있는 층(가중치가 있는 층)은 keras.layers.Layer 상속"]},{"cell_type":"code","metadata":{"id":"UMhG5kSTm7My"},"source":["class MyDense(keras.layers.Layer):\n","  def __init__(self,units, activation=None, **kwargs):\n","    super().__init__(**kwargs)\n","    self.units = units\n","    self.activation = keras.activations.get(activation)\n","  def build(self, batch_input_shape):\n","    self.kernel = self.add_weight(\n","        name=\"kernel\", shape = [batch_input_shape[-1], self.units],\n","        initializer = 'glorot_normal')\n","    self.bias = self.add_weight(\n","        name='bias', shape = [self.units],\n","        initializer = \"zeros\"\n","    )\n","    super().build(batch_input_shape)  \n","  def call(self,X):\n","    return self.activation(X @ self.kernel + self.bias)\n","  def comput_output_shape(self, batch_input_shape):\n","    return tf.TensorShape(batch_input_shape.as_list()[:-1]+\n","                          [self.units])\n","    \n","  def get_config(self):\n","    base_config = super().get_config()\n","    return {**base_config, \"units\": self.units,\n","            \"activation\": keras.activations.serialize(self.activation)}\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dheVTAovpAYd"},"source":["keras.backend.clear_session()\n","np.random.seed(42)\n","tf.random.set_seed(42)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wGe3EEbesqq0"},"source":["model = keras.models.Sequential(\n","    MyDense(30,activation='relu', input_shape=input_shape),\n","    MyDense(1)\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"O6VkymV1s_Lu"},"source":["여러가지 입력을 받는 층 ex)Concatenate"]},{"cell_type":"code","metadata":{"id":"--wqmuKcs1Le"},"source":["class MyMultiLayer(keras.layers.Layer):\n","  def call(self,X):\n","    X1,X2 = X\n","    return X1+X2, X1*X2\n","  def compute_output_shape(self,batch_input_shape):\n","    batch_input_shape1, batch_input_shape2 = batch_input_shape\n","    return [batch_input_shape1,batch_input_shape2]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SlYt8AEqtW1G"},"source":["keras.backend.clear_session()\n","np.random.seed(42)\n","tf.random.set_seed(42)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"N8rQo-VQtZqR"},"source":["inputs1 = keras.layers.Input(shape=[2])\n","inputs2 = keras.layers.Input(shape=[2])\n","#함수형 API와 서브클래싱 API에서만 사용가능. 시퀀셜에서 사용불가\n","outputs1,outputs2 = MyMultiLayer()((inputs1,inputs2))\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oLXq97EXtq4W"},"source":["훈련과 테스트에서 다르게 동작하는 층"]},{"cell_type":"code","metadata":{"id":"XrXEAAVVtmXo"},"source":["class MyGaussianNoise(keras.layers.Layer):\n","  def __init__(self,stddev,**kwargs):\n","    super().__init__(kwargs)\n","    self.stddev = stddev\n","  \n","  #call() 메서드에 trainning 매개변수를 추가하여 활용\n","  def call(self,X,training=None):\n","    if training:\n","      noise = tf.random.normal(tf.shape(X), stddev = self.stddev)\n","      return X+noise\n","    else:\n","      return X\n","\n","  def compute_output_shape(self,batch_input_shape):\n","    return batch_input_shape"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BMh0uY4SvAeH"},"source":["### 12.3.6 사용자 정의 모델"]},{"cell_type":"markdown","metadata":{"id":"E4tn6rh7wBJy"},"source":["사용자 정의 모델을 통해 ResidualBlock을 가진 모델 만들기"]},{"cell_type":"markdown","metadata":{"id":"gmiMJ3kTwowd"},"source":["블록 재사용을 위한 ResidualBlock"]},{"cell_type":"code","metadata":{"id":"X1wdB08kupi0"},"source":["class ResidualBlock(keras.layers.Layer):\n","  def __init__(self,n_layers,n_neurons,**kwargs):\n","    super().__init__(**kwargs)\n","    self.hidden=[keras.layers.Dense(n_neurons,\n","                        activation=\"elu\",\n","                        kernel_initializer=keras.initializers.he_normal)\n","    \n","    for layer in range(n_layers)]\n","\n","  def call(self,inputs):\n","    Z=inputs\n","    for layer in self.hidden:\n","      Z = layer(Z)\n","      #쭉 쌓아줌 layer(layzer(Z))\n","    return inputs+Z\n","      #마지막에 인풋과 함께 리턴\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qGwup7CRyNPg"},"source":["ResidualBlock을 사용한 ResidualRegressor 모델"]},{"cell_type":"code","metadata":{"id":"IqxtU-73yIAj"},"source":["class ResidualRegressor(keras.models.Model):\n","  def __init__(self,output_dim,**kwargs):\n","    super().__init__(kwargs)\n","    self.hidden1 = keras.layers.Dense(30,activation='elu',\n","                                      kernel_initializer='he_normal')\n","    self.block1 = ResidualBlock(2,30)\n","    self.block2 = ResidualBlock(2,30)\n","    self.out = keras.layers.Dense(output_dim)\n","  def call(self,inputs):\n","    Z = self.hidden1(inputs)\n","    #블럭1 4개\n","    for _ in range(1+3):\n","      Z = self.block1(Z)\n","    #블럭2 1개\n","    Z = self.block2(Z)\n","    return self.out(Z)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GxA4njtIzIBl"},"source":["keras.backend.clear_session()\n","np.random.seed(42)\n","tf.random.set_seed(42)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mD0Fii4azLa2"},"source":["model = ResidualRegressor(1)\n","model.compile(loss=\"mse\",optimizer= 'nadam')\n","history = model.fit(X_train_scaled, y_train,epochs=5)\n","\n","\n","\n","#일반 다른 모델과 같은 기능 가능.\n","score = model.evaluate(X_test_scaled,y_test)\n","\n","X_new_scaled = X_test_scaled\n","y_pred = model.predict(X_new_scaled)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RFJCWfU4UR6O"},"source":["### 12.3.7 모델 구성 요소에 기반한 손실과 지표"]},{"cell_type":"code","metadata":{"id":"Ql4ILsJMzlOK"},"source":["class ReconstructionRegressor(keras.Model):\r\n","  def __init__(self,output_dim,**kwargs):\r\n","    super().__init__(kwargs)\r\n","    self.hidden = [keras.layers.Dense(30,activation = \"selu\",\r\n","                                      kernel_initializer = \"lecun_normal\")\r\n","                   for _ in range(5)]\r\n","    self.out = keras.layers.Dense(output_dim)\r\n","\r\n","\r\n","  def build(self,batch_input_shape):\r\n","    n_inputs = batch_input_shape[-1]\r\n","    self.reconstruct = keras.layers.Dense(n_inputs)\r\n","    super().build(batch_input_shape)\r\n","  \r\n","  def call(self,inputs):\r\n","    Z=inputs\r\n","    for layer in self.hidden:\r\n","      Z=layer(Z)\r\n","    reconstruction = self.reconstruct(Z)\r\n","    recon_loss =tf.reduce_mean(tf.square(reconstruction - inputs))\r\n","    self.add_loss(0.05* recon_loss)\r\n","    return self.out(Z)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uwZtvvuTY3Lx"},"source":["### 12.3.8 자동 미분을 사용하여 그레디언트 계산하기"]},{"cell_type":"code","metadata":{"id":"IYkVOMKSXszZ"},"source":["def f(w1, w2):\r\n","    return 3 * w1 ** 2 + 2 * w1 * w2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gKj1irraX-QC"},"source":["w1,w2 = 5,3"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y4rEPLkWZJDG"},"source":["eps=1e-6"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"My99RjNHZh6Y"},"source":["5,3 에서 w1에 대한 도함수"]},{"cell_type":"code","metadata":{"id":"E6IfOqLwZKPE"},"source":["(f(w1+eps,w2) - f(w1,w2))/eps"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VNkIBJ7SZl6m"},"source":["5,3에서 W2에 대한 도함수"]},{"cell_type":"code","metadata":{"id":"yEy3sYNwZT4V"},"source":["(f(w1,w2+eps)-f(w1,w2))/eps"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5DzsWY8KZsBe"},"source":["텐서플로에서"]},{"cell_type":"code","metadata":{"id":"uQxeDqspZgSu"},"source":["w1,w2 = tf.Variable(5.),tf.Variable(3.)\r\n","with tf.GradientTape() as tape:\r\n","  z = f(w1,w2)\r\n","\r\n","gradient = tape.gradient(z, [w1,w2])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KnnJmgqEZ3Qa"},"source":["gradient\r\n","#일치~!"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c7wdSrz6Z6pU"},"source":["w1,w2 = tf.Variable(5.),tf.Variable(3.)\r\n","with tf.GradientTape() as tape:\r\n","  z = f(w1,w2)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ajxctDkAaPYE"},"source":["테이프는 gradient() 메서드가 호출된 후 자동으로 지워짐.\r\n","\r\n","따라서 한번이상 gradient()를 호출해야 한다면 persistent=True 후 \r\n","\r\n","테이프를 삭제하여 리소스를 해제"]},{"cell_type":"code","metadata":{"id":"cyWDit5EaJ_9"},"source":["with tf.GradientTape(persistent=True) as tape:\r\n","  z = f(w1,w2)\r\n","\r\n","dz_dw1 = tape.gradient(z,w1)\r\n","dz_dw2 = tape.gradient(z,w2)\r\n","\r\n","del tape"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Z_ITNnO9dPgl"},"source":["tape는 변수가 포함된 연산만을 기록. 아닌 변수는 None 반환"]},{"cell_type":"code","metadata":{"id":"YoRFyUIRag42"},"source":["c1,c2 = tf.constant(5.),tf.constant(3.)\r\n","#tf.Variable(변수)이 아닌 tf.constant(상수)\r\n","\r\n","\r\n","\r\n","with tf.GradientTape() as tape:\r\n","  z = f(c1,c2)\r\n","\r\n","gradients = tape.gradient(z, [c1,c2])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"q8xOQwW_dfY3"},"source":["gradients"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LVKw6dyEdwNZ"},"source":["watch를 사용하여 필요한 경우 감시하여 연산을 강제할수있음"]},{"cell_type":"code","metadata":{"id":"9p6BzsjwdhYj"},"source":["with tf.GradientTape() as tape:\r\n","  tape.watch(c1)\r\n","  tape.watch(c2)\r\n","  z = f(c1,c2)\r\n","\r\n","gradients = tape.gradient(z,[c1,c2])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CdildCjcd9hF"},"source":["gradients"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Y2Jvt8Jve_wG"},"source":["일부분에 역방향 전파만 무시시키는 방법"]},{"cell_type":"code","metadata":{"id":"ezrwbxM-d-Vk"},"source":["def f(w1,w2):\r\n","  return 3*w1**2 + tf.stop_gradient(2*w1*w2) #뒷부분은 역전파 무시 w2가 무시됨."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yUKJIU1xfQlp"},"source":["with tf.GradientTape() as tape:\r\n","  z = f(w1,w2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wKs0FBzqfWbW"},"source":["gradients = tape.gradient(z,[w1,w2])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zQPTh-6afZa7"},"source":["gradients\r\n","#w2값에 대한 역전파값이 None으로 반환."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yr5P8JxLiqi5"},"source":["데코레이터를 이용해 계산되지않는(NAN) 그레디언트 이슈 해결\r\n","\r\n","ex) softplus는 큰 입력에 대해 NAN 발생"]},{"cell_type":"markdown","metadata":{"id":"fSAV58AJinOK"},"source":["@ 데코레이터 사용법(python 문법)"]},{"cell_type":"code","metadata":{"id":"rZU23njbfaMj"},"source":["def trace(func):                             # 호출할 함수를 매개변수로 받음\r\n","    def wrapper():\r\n","        print(func.__name__, '함수 시작')    # __name__으로 함수 이름 출력\r\n","        func()                               # 매개변수로 받은 함수를 호출\r\n","        print(func.__name__, '함수 끝')\r\n","    return wrapper                           # wrapper 함수 반환\r\n"," \r\n","@trace    # @데코레이터\r\n","def hello():\r\n","    print('hello')\r\n"," \r\n","@trace    # @데코레이터\r\n","def world():\r\n","    print('world')\r\n"," \r\n","hello()    # 함수를 그대로 호출\r\n","world()    # 함수를 그대로 호출"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uEPOjvpPi3Z1"},"source":["x = tf.Variable([100.])\r\n","with tf.GradientTape() as tape:\r\n","  z= my_softplus(x)\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1iUMow67jADM"},"source":["tape.gradient(z,[x])\r\n","#soft plus가 큰 입력(100)에 대하여 nan값 출력됨."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hukh9HvGi__m"},"source":["#데코레이터를 이용한 해결\r\n","\r\n","@tf.custom_gradient\r\n","def my_better_softplus(z):\r\n","  exp = tf.exp(z)\r\n","  def my_softplus_gradients(grad):\r\n","    return grad / (1+1 / exp)\r\n","  return tf.math.log(exp+1), my_softplus_gradients\r\n","\r\n","\r\n","#이렇게하면 tf.custom_gradient 중에 이 함수가 실행됨."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yVh83DIVkY_F"},"source":["하지만 여전히 지수함수 특성상 inf값이 발생함. --> tf.where을 쓰는방법.(이게편한듯)"]},{"cell_type":"code","metadata":{"id":"846rNaMBi_3i"},"source":["def my_better_softplus(z):\r\n","    return tf.where(z > 30., z, tf.math.log(tf.exp(z) + 1.))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-FHOivEWkNP7"},"source":["x = tf.Variable([1000.])\r\n","with tf.GradientTape() as tape:\r\n","    z = my_better_softplus(x)\r\n","\r\n","z, tape.gradient(z, [x])\r\n","\r\n","#1000 vs nan"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UNCsb1EYgZnU"},"source":["12.3.9 사용자 정의 훈련 반복"]},{"cell_type":"markdown","metadata":{"id":"0U7eNUEDnUJX"},"source":["fit 메소드의 유연성 제공, but 극도의 유연성이 아니면 추천x\r\n","\r\n","\r\n","ex) wide-deep 구조처럼 경로마다 다른 옵티마이저 사용할떄"]},{"cell_type":"code","metadata":{"id":"C5DSUeRXh9Kh"},"source":["#간단한모델\r\n","l2_reg = keras.regularizers.l2(0.05)\r\n","model = keras.models.Sequential([\r\n","    keras.layers.Dense(30, activation=\"elu\", kernel_initializer=\"he_normal\",\r\n","                       kernel_regularizer=l2_reg),\r\n","    keras.layers.Dense(1, kernel_regularizer=l2_reg)\r\n","])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JGoMP2sToJ6A"},"source":["#샘플 배치를 랜덤하게 추출하는 함수\r\n","def random_batch(X, y, batch_size=32):\r\n","    idx = np.random.randint(len(X), size=batch_size)\r\n","    return X[idx], y[idx]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VRDhZJeXomR5"},"source":["#현재 스텝수, 전체 스텝수, 에포크 시작부터 평균손실 등을 포함하여 훈련상태를 출력하는 함수\r\n","\r\n","def print_status_bar(iteration, total, loss, metrics=None, size=30):\r\n","    metrics = \" - \".join([\"{}: {:.4f}\".format(m.name, m.result())\r\n","                         for m in [loss] + (metrics or [])])\r\n","    end = \"\" if iteration < total else \"\\n\"\r\n","    print(\"\\r{}/{}-\".format(iteration, total)+ metrics, end=end)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qVtzjl8PoyL9"},"source":["keras.backend.clear_session()\r\n","np.random.seed(42)\r\n","tf.random.set_seed(42)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tb5hFWS-puJi"},"source":["n_epochs = 5\r\n","batch_size = 32\r\n","n_steps = len(X_train) // batch_size\r\n","optimizer = keras.optimizers.Nadam(lr=0.01)\r\n","loss_fn = keras.losses.mean_squared_error\r\n","mean_loss = keras.metrics.Mean()\r\n","metrics = [keras.metrics.MeanAbsoluteError()]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wWmI3puqu0x-"},"source":["for epoch in range(1, n_epochs + 1):\r\n","    print(\"Epoch {}/{}\".format(epoch, n_epochs))\r\n","    for step in range(1, n_steps + 1):\r\n","        X_batch, y_batch = random_batch(X_train_scaled, y_train)\r\n","        with tf.GradientTape() as tape:\r\n","            #배치 하나를 위한 예측\r\n","            y_pred = model(X_batch)\r\n","\r\n","            #주 손실을 계산 .mse\r\n","            main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\r\n","            \r\n","            #규제손실은 하나의 스칼라 값이므로 동일한 크기와 타입을 가진 텐서를 더하는 tf.add_n()을 사용하여 손실을 모두 더함.\r\n","            loss = tf.add_n([main_loss] + model.losses)\r\n","\r\n","        #테이프를 사용해 그래디언트 계산\r\n","        gradients = tape.gradient(loss, model.trainable_variables)\r\n","        #옵티마이저에 적용해 경사하강 실행.\r\n","        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\r\n","        for variable in model.variables:\r\n","            if variable.constraint is not None:\r\n","                variable.assign(variable.constraint(variable))\r\n","        #현재 에폭에 대한 평균로스 계산(주 로스, 규제 로스).\r\n","        mean_loss(loss)\r\n","\r\n","        for metric in metrics:\r\n","            metric(y_batch, y_pred)\r\n","        print_status_bar(step * batch_size, len(y_train), mean_loss, metrics)\r\n","    print_status_bar(len(y_train), len(y_train), mean_loss, metrics)\r\n","    #평균 손실과 지표값 초기화\r\n","    for metric in [mean_loss] + metrics:\r\n","        metric.reset_states()\r\n","\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jPClzlAXWxu9"},"source":["# 12.4 텐서플로 함수와 그래프"]},{"cell_type":"markdown","metadata":{"id":"Y0T7kkmBXQbv"},"source":["파이썬 함수를 텐서플로 함수로 바꾸기"]},{"cell_type":"code","metadata":{"id":"Y6b3f_tXwPu6"},"source":["def cube(x):\n","  return x ** 3"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"k1ypi0LqXYv3"},"source":["cube(2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OagdlpsEXAeB"},"source":["cube(tf.constant(2.0))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MBmZqU5FXL3V"},"source":["tf_cube =tf.function(cube)\n","tf_cube"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eK4tr20OXfrf"},"source":["tf_cube(2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"C3vOsrsuXjuh"},"source":["tf_cube(tf.constant(2.0))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YkkjjlR3XrEV"},"source":["데코레이터를 이용하여 바꾸기"]},{"cell_type":"code","metadata":{"id":"0mygWr9JXl6W"},"source":["@tf.function\n","def tf_cube(x):\n","  return x**3"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"F29CC_J0XxtQ"},"source":["tf_cube(tf.constant(2.))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"s-4_0uBwkZvE"},"source":["어렵당 ㅡ,.ㅡ"]},{"cell_type":"markdown","metadata":{"id":"Q1Gg7DW2ks1p"},"source":["# 연습문제 12. 층 정규화를 수행하는 사용자 정의 층을 구현하시오"]},{"cell_type":"markdown","metadata":{"id":"n4tKKBXfnDSD"},"source":["\n","a.\n","_문제: build() 메서드에서 두 개의 훈련 가능한 가중치 α와 β를 정의합니다. 두 가중치 모두 크기가 input_shape[-1:]이고 데이터 타입은 tf.float32입니다. α는 1로 초기화되고 β는 0으로 초기화되어야 합니다._"]},{"cell_type":"markdown","metadata":{"id":"KNcM3yksnFye"},"source":["b.\n","문제: call() 메서드는 샘플의 특성마다 평균 μ와 표준편차 σ를 계산해야 합니다. 이를 위해 전체 샘플의 평균 μ와 분산 σ2을 반환하는 tf.nn.moments(inputs, axes=-1, keepdims=True)을 사용할 수 있습니다(분산의 제곱근으로 표준편차를 계산합니다). 그다음 α⊗(X - μ)/(σ + ε) + β를 계산하여 반환합니다. 여기에서 ⊗는 원소별 곱셈(*)을 나타냅니다. ε은 안전을 위한 항입니다(0으로 나누어지는 것을 막기 위한 작은 상수. 예를 들면 0.001)."]},{"cell_type":"code","metadata":{"id":"UhUv4k_HX0Go"},"source":["class LayerNormalization(keras.layers.Layer):\n","  def __init__(self,eps=0.001,**kwargs):\n","    super().__init__(**kwargs)\n","    self.eps = eps\n","\n","\n","  def build(self, batch_input_shape):\n","    self.alpha = self.add_weight(\n","        name='alpha',\n","        shape=batch_input_shape[-1],#(batchsize,8)인듯?.\n","        initializer =\"ones\"\n","    )\n","    \n","\n","    self.beta = self.add_weight(\n","        name='beta',\n","        shape =batch_input_shape[-1],\n","        initializer = \"zeros\"\n","    )\n","    super().build(batch_input_shape)\n","\n","\n","  def call(self,inputs):\n","    \n","    mean,variance = tf.nn.moments(inputs,axes=-1,keepdims=True)#mean,variance를 구해주는 연산\n","    return self.alpha * (inputs-mean)/(tf.sqrt(variance+self.eps)) +self.beta\n","\n","  def compute_output_shape(self,batch_input_shape):\n","    return batch_input_shape\n","\n","  \n","  def get_config(self): #얘를 쓰는 이유는 뭐라고?? --> 모델 저장 시 파라미터까지 함께 저장하고 싶을떄.\n","    base_config = super().get_config()\n","    return {**base_config, \"eps\": self.eps}\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Mq6BjR0gnwEd"},"source":["c.\n","문제: 사용자 정의 층이 keras.layers.LayerNormalization 층과 동일한(또는 거의 동일한) 출력을 만드는지 확인하세요.\n","각 클래스의 객체를 만들고 데이터(예를 들면, 훈련 세트)를 적용해 보죠. 차이는 무시할 수 있는 수준입니다."]},{"cell_type":"code","metadata":{"id":"uqNvauXJnr7r"},"source":["X= X_train.astype(np.float32)\n","\n","custom_layer_norm = LayerNormalization()\n","keras_layer_norm = keras.layers.LayerNormalization()\n","\n","tf.reduce_mean(keras.losses.mean_absolute_error(\n","    keras_layer_norm(X), custom_layer_norm(X)))\n","\n","\n","\n","#두 값이 가까움. 5.496049e-08 --> 사용자 정의 층과 케라스 층이 비슷한 결과를 냄."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tQrl9K1lsSwr"},"source":["13. 사용자 정의 훈련 반복을 사용해 패션 MNIST 데이터셋으로 모델을 훈련해보세요."]},{"cell_type":"markdown","metadata":{"id":"eycy1hcNuNW3"},"source":["데이터 준비"]},{"cell_type":"code","metadata":{"id":"A0DeeqEXrE3V"},"source":["(X_train_full,y_train_full),(X_test,y_test) = keras.datasets.fashion_mnist.load_data()\n","\n","X_train_full = X_train_full.astype(np.float32)/255.\n","X_test = X_test.astype(np.float32)/255.\n","\n","X_train,X_valid =X_train_full[5000:],X_train_full[:5000]\n","y_train,y_valid = y_train_full[5000:],y_train_full[:5000]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RLHR7735uKOe"},"source":["keras.backend.clear_session()\n","np.random.seed(42)\n","tf.random.set_seed(42)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QX3FCoZTuXCw"},"source":["model = keras.models.Sequential([\n","                                 keras.layers.Flatten(input_shape=[28,28]),\n","                                 keras.layers.Dense(100,activation='relu'),\n","                                 keras.layers.Dense(10,activation='softmax')\n","])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LHvFCMtmuw4r"},"source":["n_epochs=5\n","batch_size=32\n","n_steps = len(X_train)//batch_size\n","optimizer = keras.optimizers.Nadam(lr=0.01)\n","loss_fn = keras.losses.sparse_categorical_crossentropy\n","mean_loss = keras.metrics.Mean()\n","metrics = [keras.metrics.SparseCategoricalAccuracy)]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"olvYV1swvFhP"},"source":["from tqdm.notebook import trange\n","from collections import OrderedDict\n","#epoch tqdm\n","with trange(1,n_epochs+1, desc = \"All epochs\") as epochs:\n","  for epoch in epochs:\n","    #step tqdm\n","    with trange(1,n_steps+1,desc = \"Epoch {}/{}\".format(epoch,n_epochs)) as steps:\n","      for step in steps:\n","        X_batch,y_batch = random_batch(X_train,y_train)\n","        \n","        with tf.GradientTape() as tape:\n","          y_pred = model(X_batch)\n","          main_loss = tf.reduce_mean(loss_fn(y_batch,y_pred))\n","          loss = tf.add_n([main_loss]+model.losses)\n","        gradient = tape.gradient(loss,model.trainable_variables)\n","        optimizer.apply_gradients(zip(gradient,model.trainable_variables))\n","\n","        \n","        #저장\n","        status =OrderedDict()\n","        mean_loss(loss)\n","        status[\"loss\"] = mean_loss.result().numpy()\n","\n","        for metric in metrics:\n","          \n","          metric(y_batch,y_pred)\n","          status[metric.name] = metric.result().numpy()\n","        steps.set_postfix(status) # tqdm 기록 해주는 함수인듯\n","      y_pred = model(X_valid)\n","      status[\"val_loss\"] =np.mean(loss_fn(y_valid,y_pred))\n","      status[\"val_accuracy\"] = np.mean(keras.metrics.sparse_categorical_accuracy(\n","          tf.constant(y_valid,dtype = np.float32), y_pred\n","      )) \n","      steps.set_postfix(status) \n","    for metric in [mean_loss] + metrics:\n","      metric.reset_states()\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2h8iYzOc2xJz"},"source":["b.\n","문제: 상위 층과 하위 층에 학습률이 다른 옵티마이저를 따로 사용해보세요."]},{"cell_type":"code","metadata":{"id":"7KszcXcnvikH"},"source":["keras.backend.clear_session()\n","np.random.seed(42)\n","tf.random.set_seed(42)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nF4WJyHG3iwL"},"source":["하위층 상위층 생성"]},{"cell_type":"code","metadata":{"id":"Zi9yYdJ13HUi"},"source":["lower_layers = keras.models.Sequential([\n","                                        \n","keras.layers.Flatten(input_shape=[28,28]),\n","keras.layers.Dense(100,activation='relu')\n","])\n","\n","upper_layers = keras.models.Sequential([\n","                                        \n","keras.layers.Dense(10,activation='softmax'),\n","\n","])\n","\n","model = keras.models.Sequential([\n","  lower_layers,upper_layers\n","])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HvYwhEdX3tFy"},"source":["상위층 하위층 옵티마이저 생성"]},{"cell_type":"code","metadata":{"id":"98IoW1aM3fIU"},"source":["lower_optimizer= keras.optimizers.SGD(lr=1e-4)\n","upper_optimizer = keras.optimizers.Nadam(lr=1e-3)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"l5owhk5U3sia"},"source":["n_epochs=5\n","batch_size=32\n","n_steps = len(X_train)//batch_size\n","loss_fn = keras.losses.sparse_categorical_crossentropy\n","mean_loss = keras.metrics.Mean()\n","metrics = [keras.metrics.SparseCategoricalAccuracy()]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5pMDwy3l4B_E"},"source":["사용자 정의 훈련 반복"]},{"cell_type":"code","metadata":{"id":"TAlKREZF4AFk"},"source":["#에폭 tqdm\n","with trange(1,n_epochs+1, desc=\"All epochs\") as epochs:\n","  for epoch in epochs:\n","    with trange(1,n_steps+1, desc = \"{}/{}\".format(epoch,n_epochs)) as steps:\n","      for step in steps:\n","        X_batch,y_batch = random_batch(X_train,y_train)\n","\n","\n","              #두번 쓰기 위해 persistent = True 설정\n","        with tf.GradientTape(persistent=True) as tape:\n","          y_pred = model(X_batch)\n","          main_loss = tf.reduce_mean(loss_fn(y_batch,y_pred))\n","          loss = tf.add_n([main_loss]+model.losses)\n","\n","        #옵티마이저 각각 적용\n","        for layers,optimizer in ((lower_layers,lower_optimizer),(upper_layers,upper_optimizer)):\n","          gradients = tape.gradient(loss,layers.trainable_variables)\n","          optimizer.apply_gradients(zip(gradients,layers.trainable_variables))\n","        #persistent=True 이므로 수동삭제\n","        del tape\n","      \n","\n","        status = OrderedDict()\n","\n","        mean_loss(loss)\n","        status[\"loss\"] = mean_loss.result().numpy()\n","\n","        for metric in metrics:\n","          metric(y_batch,y_pred)\n","          status[metric.name] = metric.result().numpy()\n","        \n","        steps.set_postfix(status)\n","      y_pred = model(X_valid)\n","      status[\"val_loss\"] = np.mean(keras.metrics.sparse_categorical_accuracy(\n","          tf.constant(y_valid,dtype=np.float32),y_pred\n","      ))\n","\n","      steps.set_postfix(status)\n","\n","  for metric in [mean_loss] + metrics:\n","    metric.reset_states()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nKx_NmGo7Sp0"},"source":[""],"execution_count":null,"outputs":[]}]}